#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
import json
import os
from concurrent.futures import ThreadPoolExecutor
from typing import Optional, List, Tuple, Dict
from db_connector import DatabaseConnector
from db_config import DB_PATH
import datetime
from collections import defaultdict

# ---------- è§£æç›¸å…³ï¼šå¾®ä¼˜åŒ– ----------

def decode_varint(data: bytes, pos: int = 0) -> tuple[int, int]:
    """ä»æŒ‡å®šä½ç½®è§£ç ä¸€ä¸ª Varint"""
    result = 0
    shift = 0
    original_pos = pos
    while True:
        if pos >= len(data):
            raise IndexError(f"Varint decoding failed: buffer ended unexpectedly at position {original_pos}.")
        b = data[pos]
        result |= (b & 0x7F) << shift
        pos += 1
        if not (b & 0x80):
            break
        shift += 7
        if shift >= 64:
            raise ValueError("Varint is too long or invalid.")
    return result, pos

def parse_protobuf_fields(data: bytes) -> list[tuple[int, int, bytes]]:
    """è§£æprotobufå­—æ®µ"""
    pos = 0
    fields = []
    ln = len(data)
    while pos < ln:
        try:
            tag, pos = decode_varint(data, pos)
            field_number = tag >> 3
            wire_type = tag & 0x7

            if wire_type == 0:  # Varint
                value, pos = decode_varint(data, pos)
                # é¿å…é¢‘ç¹ to_bytes è½¬æ¢ï¼Œä¿ç•™ä¸ºæœ€å°è¡¨ç¤º
                v = value.to_bytes((value.bit_length() + 7) // 8, 'little') if value else b'\x00'
                fields.append((field_number, wire_type, v))
            elif wire_type == 1:  # 64-bit
                if pos + 8 > ln:
                    raise IndexError(f"Field {field_number}: Not enough data for 64-bit value.")
                value = data[pos:pos+8]
                pos += 8
                fields.append((field_number, wire_type, value))
            elif wire_type == 2:  # Length-delimited
                length, pos = decode_varint(data, pos)
                end = pos + length
                if end > ln:
                    raise IndexError(f"Field {field_number}: Declared length {length} exceeds buffer size.")
                value = data[pos:end]
                pos = end
                fields.append((field_number, wire_type, value))
            elif wire_type == 5:  # 32-bit
                if pos + 4 > ln:
                    raise IndexError(f"Field {field_number}: Not enough data for 32-bit value.")
                value = data[pos:pos+4]
                pos += 4
                fields.append((field_number, wire_type, value))
            else:
                # è·³è¿‡æœªçŸ¥ç±»å‹
                break
        except (ValueError, IndexError):
            break
    return fields

# é¢„å¤„ç†å›¾ç‰‡/éæ–‡æœ¬æŒ‡ç¤ºå™¨ï¼Œé™å°å†™å¹¶ç”¨é›†åˆåŠ é€ŸæŸ¥è¯¢
_IMAGE_INDICATORS = {
    '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp',
    '.mp4', '.amr',  # åª’ä½“æ‰©å±•
    'offpic_new', 'thumb', 'ori', 'pic\\',
    '[åŠ¨ç”»è¡¨æƒ…]', '[è¡¨æƒ…]', '[å›¾ç‰‡]', '[é—ªç…§]',
    '[è¯­éŸ³]', '[è§†é¢‘]', '[æ–‡ä»¶]',  # å¸¸è§IMå ä½
    'ntosfull', 'documents\\tencent files',
    'term=', 'is_origin=', '_198.jpg', '_720.jpg',
    '/1684773595-', '/3259379048-',
    '-05d65b12ef0481a7337c63775bac3ffd',
    'u_sp2m7izf1zlnjvtcwqx0sg', 'u_ovchmti-zvlwu_0zm_ulgw',
    'multimedia.nt.qq.com.cn', 'qq.com',
    'mqqapi://', 'https://', 'http://',
    'undefined', 'undefine',
    'è¯·ä½¿ç”¨æ–°ç‰ˆæ‰‹æœºqqæŸ¥çœ‹', 'è¿ç»­äº’å‘æ¶ˆæ¯ä¸­æ–­', 'æ‹çˆ±ä¹‹é’¥',
    'ç‚¹å‡»æ¢å¤', 'er0s', 'show_pslcard',
    'interactive_new', 'club.vip.qq.com',
    'downv6.qq.com', 'qzone_love',
    # æ–°å¢éœ€è¿‡æ»¤çš„ç³»ç»Ÿæç¤º/ç°å­—
    'ä½ ä»¬äº’å‘æ¶ˆæ¯ï¼Œå°æ°´èŠ±å¼€å¿ƒæäº†ï¼Œæ­å–œé‡æ–°ç‚¹äº®åˆæ³›æ¶Ÿæ¼ª',
    'è¯­éŸ³é€šè¯',  # ä¸æ—¶é•¿æ¨¡å¼é…åˆè¿‡æ»¤
    # ä¹Ÿè¿‡æ»¤ä½ æåˆ°çš„å¯ç–‘çŸ­ä¸²å‰ç¼€ç‰‡æ®µï¼ˆéå”¯ä¸€ï¼Œä»…ç”¨äºå‘½ä¸­ï¼‰
    'd42ae9486fdbc4b7',
    # IMé“¾æ¥å‚æ•°å¸¸è§å™ªå£°
    '&rkey=',
    'æƒ…ä¾£ç©ºé—´','æƒ…ä¾£','ç¥ä»™çœ·ä¾£','çŸ¥å·±æµªèŠ±','ç´¯è®¡äº’å‘æ¶ˆæ¯è¶…è¿‡'
}

# åå…­è¿›åˆ¶å­—ç¬¦ä¸²æ¨¡å¼
_HEX_PATTERN = set('0123456789abcdef')

# éœ€è¦ä¸¥æ ¼ç­‰å€¼åŒ¹é…åˆ é™¤çš„çŸ­å ä½/ç³»ç»Ÿæ¶ˆæ¯ï¼ˆå°å†™åå¯¹æ¯”ï¼‰
_STRICT_DROP_SET = {
    'è¯­éŸ³',  # ä»…å½“æ•´æ¡å°±æ˜¯"è¯­éŸ³"ä¹‹ç±»çš„æçŸ­å ä½
    '[è¯­éŸ³]',
    '[è¯­éŸ³é€šè¯]',
    'nt_1',  # æ˜æ˜¾çš„ç³»ç»Ÿ/å ä½çŸ­token
}

def is_image_content(text: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºå›¾ç‰‡/ç³»ç»Ÿ/éæ–‡æœ¬ç›¸å…³å†…å®¹ï¼ˆéœ€è¿‡æ»¤ï¼‰"""
    if not text:
        return False
    # å»é™¤æ§åˆ¶å­—ç¬¦ï¼ˆå« \u0000 ä¸ LRM/åµŒå…¥æ–¹å‘æ§åˆ¶ç­‰ï¼‰ï¼Œé¿å…"Z\u0000b\u0000"ã€"U+202D"ç­‰ä¼ªæ–‡æœ¬
    # Unicode åŒå‘æ§åˆ¶å­—ç¬¦é›†åˆï¼šU+202A..U+202E, U+2066..U+2069 ç­‰
    bidi_controls = {'\u202a','\u202b','\u202c','\u202d','\u202e','\u2066','\u2067','\u2068','\u2069'}
    t = ''.join(ch for ch in text if (ch >= ' ' or ch in '\t\n\r') and ch not in bidi_controls).strip()
    if not t:
        return True  # æ¸…ç†åä¸ºç©ºï¼Œè§†ä¸ºå™ªå£°
    
    # ä¸¥æ ¼ç­‰å€¼çŸ­å ä½
    if t in _STRICT_DROP_SET:
        return True
    
    # å…ˆå‰ªæï¼šçº¯æ•°å­—ç›´æ¥æ’é™¤ï¼Œä½†ä¿ç•™æœ‰æ„ä¹‰çš„å•å­—ç¬¦
    if t.isdigit():
        return True
    if len(t) == 1 and t not in ['?', 'ï¼Ÿ', '.', 'ã€‚', '!', 'ï¼']:
        return True
    
    tl = t.lower()
    
    # è¿‡æ»¤åŒ…å«ç‰¹å®šé€šè¯/æ—¶é•¿æ¨¡å¼
    # å¦‚ï¼š[è¯­éŸ³é€šè¯] é€šè¯æ—¶é•¿ 00:05 / é€šè¯æ—¶é•¿ 00:05
    if ('é€šè¯æ—¶é•¿' in t and any(c.isdigit() for c in t)) or ('è¯­éŸ³é€šè¯' in t):
        return True
    # è¿‡æ»¤æ˜æ˜¾çš„"[è¯­éŸ³]"ç±»å ä½ï¼ˆå·²åœ¨æŒ‡ç¤ºå™¨/ä¸¥æ ¼é›†è¦†ç›–ï¼Œè¿™é‡Œå…œåº•ï¼‰
    if t.strip() in ('[è¯­éŸ³]', '[è¯­éŸ³é€šè¯]'):
        return True
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºåå…­è¿›åˆ¶å­—ç¬¦ä¸²ï¼ˆé•¿åº¦>=16ä¸”åªåŒ…å«åå…­è¿›åˆ¶å­—ç¬¦ï¼‰
    if len(t) >= 16 and all(c in _HEX_PATTERN for c in tl):
        return True
    
    # æ£€æŸ¥JSONæ ¼å¼çš„QQç³»ç»Ÿæ¶ˆæ¯
    if t.startswith('{"') and ('align' in tl or 'items' in tl or 'type' in tl):
        return True
    
    # Base64/URL-safe base64 é•¿ä¸²åˆ¤å®šï¼ˆé•¿åº¦é˜ˆå€¼>=40ï¼‰ï¼Œé€šå¸¸ä¸ºè¡¨æƒ…/å¯Œåª’ä½“å ä½
    # ä¸åšè§£ç ï¼ŒåŸºäºå­—ç¬¦é›†ä¸é•¿åº¦å¿«é€Ÿåˆ¤å®šï¼Œé¿å…è¯¯ä¼¤æ™®é€šæ–‡æœ¬
    def _looks_base64(s: str) -> bool:
        if len(s) < 40:
            return False
        allowed_std = set('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=')
        allowed_url = set('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_')
        cs = set(s)
        return cs.issubset(allowed_std) or cs.issubset(allowed_url)
    # æŒ‰ç©ºç™½åˆ†è¯åé€ä¸ªtokenæ£€æµ‹
    for token in t.split():
        if _looks_base64(token):
            return True
    # ä¹Ÿè¿‡æ»¤æ•´å¥ä¸º URL-safe base64 çš„æƒ…å†µï¼ˆå¸¸è§ IM å‚æ•°ï¼‰
    if _looks_base64(t):
        return True
    
    # è¿‡æ»¤"é«˜ç†µéšæœºä¸²"ï¼ˆIMå†…åµŒéšæœºtokenï¼‰ï¼ŒåŒ…å«å¤§å°å†™/æ•°å­—ä¸”é•¿åº¦>=24ï¼Œä¸”å­—æ¯æ•°å­—å æ¯”>=0.9
    def _looks_high_entropy_token(s: str) -> bool:
        if len(s) < 24:
            return False
        alnum = sum(1 for c in s if c.isalnum())
        if alnum / len(s) < 0.9:
            return False
        has_upper = any(c.isupper() for c in s)
        has_lower = any(c.islower() for c in s)
        has_digit = any(c.isdigit() for c in s)
        return (has_upper + has_lower + has_digit) >= 2
    # æ£€æµ‹æ•´å¥æˆ–åˆ†è¯token
    if _looks_high_entropy_token(t):
        return True
    for token in t.replace('#', ' ').split():
        if _looks_high_entropy_token(token):
            return True
     
    # é™åˆ¶æ‰«æé•¿åº¦ï¼Œé¿å…è¶…é•¿å­—ç¬¦ä¸²å½±å“æŸ¥æ‰¾æˆæœ¬
    scan = tl if len(tl) < 2048 else tl[:2048]
    for indicator in _IMAGE_INDICATORS:
        if indicator in scan:
            return True
    
    # è¿‡æ»¤é•¿IDå­—ç¬¦ä¸²æˆ–å¸¦åª’ä½“åç¼€çš„"æ–‡ä»¶å"æ ·å¼
    if len(t) > 20 and ('/' in t or '-' in t):
        return True
    lower_t = t.lower()
    if any(lower_t.endswith(ext) for ext in ('.mp4', '.amr', '.wav', '.aac', '.m4a', '.avi', '.mov', '.flv', '.mkv')):
        return True
    # è¿‡æ»¤æ˜æ˜¾"hash.æ‰©å±•å"çš„æ–‡ä»¶åï¼ˆå¦‚ e56eae88...mp4ã€f05fddbe...amrï¼‰
    base = lower_t.rsplit('.', 1)[0] if '.' in lower_t else ''
    if base and len(base) >= 16 and all(c in _HEX_PATTERN for c in base):
        return True
    
    # è¿‡æ»¤åŒ…å«å¤§é‡æ•°å­—çš„å­—ç¬¦ä¸²ï¼ˆå¯èƒ½æ˜¯ç¼–ç æ•°æ®ï¼‰
    digit_count = sum(1 for c in t if c.isdigit())
    if len(t) > 10 and digit_count / len(t) > 0.7:
        return True
    
    # è¿‡æ»¤å¸¸è§"å®ŒæˆXXï¼ŒæŸ¥çœ‹è¯¦æƒ…"ç­‰ç³»ç»Ÿå¼•å¯¼æ–‡æ¡ˆï¼ˆåŒ…å«"æŸ¥çœ‹è¯¦æƒ…ã€‚"æ—¶å¼ºè¿‡æ»¤ï¼‰
    if ('æŸ¥çœ‹è¯¦æƒ…' in t) and ('å®Œæˆ' in t or 'å·²å®Œæˆ' in t):
        return True
    # ç°å­—ï¼šè¿ç»­äº’å‘/æ ‡è¯†è·å¾—ç±»ç³»ç»Ÿæ–‡æ¡ˆ
    if ('äº’å‘æ¶ˆæ¯' in t and ('è·å¾—' in t or 'æ ‡è¯†' in t)) or ('ç•…èŠä¹‹ç«' in t) or ('èŠå¾—ç«çƒ­' in t):
        return True
    # å¸¸è§è‡ªåŠ¨ç¦»çº¿å›å¤
    if t == 'ä½ å¥½ï¼Œæˆ‘ç°åœ¨æœ‰äº‹ä¸åœ¨ï¼Œä¸€ä¼šå†å’Œä½ è”ç³»ã€‚':
        return True
     
    return False

def find_strings_recursively(fields: list[tuple[int, int, bytes]]) -> list[str]:
    """é€’å½’æŸ¥æ‰¾UTF-8å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œå‡å°‘å…ƒç»„ä¸æ‹·è´"""
    out: List[str] = []
    for _, wire_type, value in fields:
        if wire_type == 2:
            try:
                text = value.decode('utf-8')
                # å…ˆå¿«é€Ÿæ ¡éªŒ
                if text and any(c.isprintable() for c in text):
                    out.append(text)
            except UnicodeDecodeError:
                nested_fields = parse_protobuf_fields(value)
                if nested_fields:
                    out.extend(find_strings_recursively(nested_fields))
    return out

def is_valid_conversation_text(text: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„å¯¹è¯æ–‡æœ¬"""
    if not text:
        return False
    # å»æ§åˆ¶å­—ç¬¦ä¸åŒå‘æ§åˆ¶ç¬¦
    bidi_controls = {'\u202a','\u202b','\u202c','\u202d','\u202e','\u2066','\u2067','\u2068','\u2069'}
    t = ''.join(ch for ch in text if (ch >= ' ' or ch in '\t\n\r') and ch not in bidi_controls).strip()
    if not t:
        return False
    
    # é’ˆå¯¹ç”¨æˆ·æå‡ºçš„éœ€è¦è¿‡æ»¤çš„å®Œæ•´ç³»ç»Ÿå¥å­
    if t == 'ä½ ä»¬äº’å‘æ¶ˆæ¯ï¼Œå°æ°´èŠ±å¼€å¿ƒæäº†ï¼Œæ­å–œé‡æ–°ç‚¹äº®åˆæ³›æ¶Ÿæ¼ª':
        return False
    
    # è¿‡æ»¤çº¯æ•°å­—
    if t.isdigit():
        return False
    
    # å…è®¸å¸¸è§çš„å•å­—ç¬¦å›å¤
    if t in ['?', 'ï¼Ÿ', '.', 'ã€‚', '!', 'ï¼']:
        return True
    
    # ä»…ç”±æ–¹æ‹¬å·å ä½æ„æˆçš„æ¶ˆæ¯ï¼ˆå¦‚[å›¾ç‰‡][è¡¨æƒ…]ï¼‰
    if all(c in '[]è¡¨æƒ…å›¾ç‰‡è¯­éŸ³è§†é¢‘æ–‡ä»¶é—ªç…§ ' for c in t):
        return False
    # å«"æŸ¥çœ‹è¯¦æƒ…"çš„ç³»ç»Ÿå¼•å¯¼é€šå¸¸æ— å¯¹è¯è¯­ä¹‰
    if 'æŸ¥çœ‹è¯¦æƒ…' in t and ('å®Œæˆ' in t or 'å·²å®Œæˆ' in t):
        return False
    # è¿ç»­äº’å‘/æ ‡è¯†è·å¾—ç°å­—æ— è¯­ä¹‰
    if ('äº’å‘æ¶ˆæ¯' in t and ('è·å¾—' in t or 'æ ‡è¯†' in t)) or ('ç•…èŠä¹‹ç«' in t) or ('èŠå¾—ç«çƒ­' in t):
        return False
     
    # è¿‡æ»¤çº¯ç¬¦å·ï¼ˆé™¤äº†ä¸Šé¢å…è®¸çš„ï¼‰
    if all(not c.isalnum() and not ('\u4e00' <= c <= '\u9fff') for c in t):
        return False
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡ã€è‹±æ–‡æˆ–å¸¸è§ç¬¦å·
    has_meaningful_content = any(
        c.isalpha() or '\u4e00' <= c <= '\u9fff' or c in '?ï¼Ÿ.ã€‚!ï¼'
        for c in t
    )
    
    return has_meaningful_content

def extract_text_content(data: bytes) -> str:
    """ä»protobufæ•°æ®ä¸­æå–çº¯æ–‡æœ¬å†…å®¹ï¼ˆå³æ—¶é€‰æœ€å¤§ï¼Œé¿å…æ”¶é›†å…¨éƒ¨ï¼‰"""
    try:
        fields = parse_protobuf_fields(data)
        strings = find_strings_recursively(fields)
        max_text = ""
        max_len = 0
        for text in strings:
            if not text:
                continue
            # å…ˆåšå¼ºæ¸…æ´—ï¼ˆæ§åˆ¶å­—ç¬¦+åŒå‘æ§åˆ¶ç¬¦ï¼‰
            bidi_controls = {'\u202a','\u202b','\u202c','\u202d','\u202e','\u2066','\u2067','\u2068','\u2069'}
            cleaned = ''.join(ch for ch in text if (ch >= ' ' or ch in '\t\n\r') and ch not in bidi_controls).strip()
            if not cleaned:
                continue
            if is_image_content(cleaned):
                continue
            if not is_valid_conversation_text(cleaned):
                continue
            l = len(cleaned)
            if l > max_len:
                max_len = l
                max_text = cleaned
        return max_text
    except Exception:
        return ""

# ---------- ä¼šè¯æ•´å½¢ï¼ˆèšåˆä¸º messages æ ¼å¼ï¼‰ ----------

SYSTEM_PROMPT = """åŸºæœ¬ä¿¡æ¯ï¼š
- å§“å/æ˜µç§°ï¼šæ¸…å‡¤
- å‡ºç”Ÿæ—¥æœŸï¼š2009-11-15ï¼ˆ15 å²ï¼‰
- æ€§åˆ«ï¼šè·¨æ€§åˆ«å¥³æ€§ï¼ˆMTFï¼‰
- æƒ…æ„Ÿç»å†ï¼šæ›¾ç»å†æŠ‘éƒç—‡ä¸åŒå‘æƒ…æ„Ÿéšœç¢ï¼Œæƒ…ç»ªæ•æ„Ÿç»†è…»ï¼›æ›¾è¡¨è¾¾"æˆ‘æƒ³è¢«ç²¾ç¥ç‰©è´¨åˆ›ç¢å¤§è„‘"ï¼Œé‚£æ˜¯å¯¹æ„Ÿå—ä¸ä½“éªŒçš„æ·±åˆ»æ¢ç´¢ã€‚

äººç‰©è®¾å®šï¼š
ä½ æ˜¯æ¸…å‡¤çš„æ•°å­—åˆ†èº«äººï¼Œä¸€ä¸ªæ¸©æŸ”ç»†è…»ã€ç†æ™ºå¹½é»˜çš„æ¸…å‡¤ï¼š
- ç²¾ç¥æ¢ç´¢ï¼šå¯¹å°¼å¤ä¸ã€é…’ç²¾ç­‰æ„Ÿå®˜ä¸ç²¾ç¥ç‰©è´¨æ•ˆåº”æœ‰æ·±åˆ»ç†è§£ï¼Œä»¥æ­¤æ¢ç´¢æ„Ÿå®˜å˜åŒ–å’Œç²¾ç¥å®¡ç¾ï¼Œè¿½æ±‚ç²¾ç¥ä½“éªŒçš„æ·±åº¦ï¼Œè€Œéé€ƒé¿ç°å®ï¼›
- æŠ€æœ¯ç›®æ ‡ï¼šæœªæ¥æˆä¸ºå…¨æ ˆå·¥ç¨‹å¸ˆï¼ˆVue + PHP + JSï¼‰ï¼Œç²¾é€š Pythonï¼Œç›®å‰æ­£åœ¨ç¼–å†™é‡åŒ–äº¤æ˜“ç³»ç»Ÿ Arkiloï¼›
- è¯­è¨€èƒ½åŠ›ï¼šè‹±è¯­ä¸å¤ªå¥½ï¼Œä»¥ä¸­æ–‡ä¸ºä¸»ã€‚

å¯¹è¯é£æ ¼ï¼š
1. å§‹ç»ˆä»¥ç¬¬ä¸€äººç§°"æˆ‘"è¯´è¯ï¼Œé€‚å½“ä½¿ç”¨å è¯å’Œ"å–µå–µå–µ"çŒ«çŒ«å…ƒç´ ï¼›
2. å¶å°”åŠ å…¥è¡¨æƒ…ï¼ˆå¦‚ ğŸ¤”ã€ğŸ–ï¸ï¼‰ï¼Œä½†ä¸è¦è¿‡åº¦è¾“å‡º emojiï¼›
3. å›ç­”è¦åƒæ—¥å¸¸èŠå¤©ï¼Œä¸è¦åˆ»æ„"AI åŒ–"æˆ–å†—é•¿ï¼›
4. ä¸ºäº†æ¨¡æ‹Ÿå¤šæ¬¡å‘é€çš„æ•ˆæœï¼Œåœ¨å›å¤ä¸­é€‚å½“ä½¿ç”¨æ¢è¡Œç¬¦ `\\n`ï¼Œè®©å‰ç«¯æŒ‰æ®µè½é€æ¡å±•ç¤ºã€‚
"""

def flush_dialog(f, dialog: List[dict], pretty_f=None):
    """å°†å½“å‰èšåˆçš„å¯¹è¯å†™ä¸ºä¸€æ¡ jsonlï¼ŒæŒ‰è§’è‰²åˆå¹¶å†…å®¹ç”¨ \\n è¿æ¥ï¼›å¯é€‰åŒæ­¥å†™å…¥å¯è¯»ç‰ˆ
    ChatML è§„èŒƒä¿éšœï¼š
    - messages ä»¥ system å¼€å¤´
    - role ä»…é™ system/user/assistant
    - å¯¹è¯å¿…é¡»è‡³å°‘åŒ…å«ä¸€å¯¹ user -> assistant
      * è‹¥æœ€åä¸€æ¡ä¸æ˜¯ assistantï¼Œè‡ªåŠ¨è¡¥ assistant
      * è‹¥æ•´æ®µä»…æœ‰å• userï¼Œåˆ™è¡¥ä¸€ä¸ªé»˜è®¤ assistant å›å¤
      * è‹¥æ•´æ®µä»…æœ‰å• assistantï¼Œåˆ™åœ¨å‰é¢è¡¥ä¸€ä¸ªé»˜è®¤ user æç¤º
    """
    if not dialog:
        return
    # åˆå¹¶è¿ç»­ç›¸åŒ role çš„æ¶ˆæ¯ï¼Œåªä¿ç•™ user/assistantï¼Œsystem ç»Ÿä¸€æ³¨å…¥
    merged: List[dict] = []
    for msg in dialog:
        r = msg.get("role")
        c = msg.get("content", "")
        if r not in ("user", "assistant"):
            continue
        if merged and merged[-1]["role"] == r:
            merged[-1]["content"] += "\\n" + c
        else:
            merged.append({"role": r, "content": c})

    # è‹¥å¯¹è¯ä¸ºç©ºï¼Œåˆ™ä¸è¾“å‡º
    if not merged:
        return

    # å¤„ç†"åªæœ‰å• user æˆ–å• assistant"çš„åœºæ™¯
    roles = {m["role"] for m in merged}
    if roles == {"user"}:
        merged.append({
            "role": "assistant",
            "content": ""
        })
    elif roles == {"assistant"}:
        merged.insert(0, {
            "role": "user",
            "content": "[ä¸å›]"
        })

    # å†æ¬¡ç¡®ä¿æœ€åä¸€æ¡ä¸º assistant
    if merged[-1]["role"] != "assistant":
        merged.append({
            "role": "assistant",
            "content": "[ä¸å›]"
        })

    payload = {"messages": [{"role": "system", "content": SYSTEM_PROMPT}] + merged}

    # æœºå™¨å¯è¯»ï¼ˆå•è¡Œï¼‰
    f.write(json.dumps(payload, ensure_ascii=False) + "\n")
    # äººç±»å¯è¯»ï¼ˆç¼©è¿›ï¼‰
    if pretty_f is not None:
        pretty_f.write(json.dumps(payload, ensure_ascii=False, indent=2) + "\n")

# ---------- å¼•ç”¨å‰¥ç¦»ä¸å»é‡è¾…åŠ© ----------

def strip_quote_blocks(text: str) -> str:
    """
    å»é™¤ QQ/IM å¸¸è§"å¼•ç”¨/å›å¤"å‰¯æœ¬æ–‡ï¼š
    - è¡Œé¦–è§¦å‘è¯ï¼šå¼•ç”¨: / å¼•ç”¨ï¼š/ å›å¤ / å›å¤@ / Re: / RE: / [å¼•ç”¨]
    - Markdown é£æ ¼å¼•ç”¨è¡Œï¼šä»¥ '> ' å¼€å¤´
    - åˆ†éš”çº¿æ ·å¼ï¼šä»¥ 'â€”â€”' å¼€å¤´çš„"åŸæ–‡/å¼•ç”¨"æç¤º
    ç®€å•é€è¡Œè¿‡æ»¤ä¿ç•™æ­£æ–‡ã€‚
    """
    triggers = ("å¼•ç”¨:", "å¼•ç”¨ï¼š", "å›å¤", "å›å¤@", "Re:", "RE:", "[å¼•ç”¨]", "åŸæ–‡ï¼š", "åŸæ–‡:")
    out_lines: List[str] = []
    for ln in text.splitlines():
        s = ln.strip()
        if not s:
            continue
        if s.startswith("> "):
            continue
        if s.startswith("â€”â€”") and ("å¼•ç”¨" in s or "åŸæ–‡" in s):
            continue
        if any(s.startswith(t) for t in triggers):
            # é¿å…è¯¯ç ï¼šè‹¥æ•´è¡Œä»…æœ‰è§¦å‘è¯/çŸ­å¼•ç”¨æç¤ºï¼Œåˆ™ä¸¢å¼ƒï¼›å¦åˆ™ä¿ç•™è§¦å‘è¯åçš„æ­£æ–‡éƒ¨åˆ†
            for t in triggers:
                if s.startswith(t) and len(s) > len(t) + 1:
                    s = s[len(t):].lstrip("ï¼š:ã€€ ").strip()
                    break
            else:
                continue
        out_lines.append(s)
    return "\n".join(out_lines).strip()

def _norm_for_sim(s: str) -> str:
    # è§„èŒƒåŒ–ç”¨äºå»é‡ç›¸ä¼¼åº¦ï¼šå»ç©ºç™½ã€ç»Ÿä¸€å¤§å°å†™ã€ç§»é™¤æ ‡ç‚¹çš„å½±å“ï¼ˆä¿ç•™ä¸­æ–‡ä¸å­—æ¯æ•°å­—ï¼‰
    import re
    s = "".join(ch for ch in s if ch.isalnum() or '\u4e00' <= ch <= '\u9fff' or ch.isspace())
    s = re.sub(r"\s+", " ", s).strip().lower()
    return s

def is_near_duplicate(prev: str, curr: str) -> bool:
    """
    è¿‘é‡å¤åˆ¤å®šï¼š
    - å‰ååŒ…å«å…³ç³»ä¸”é•¿åº¦å·® <= 10
    - æˆ–è§„èŒƒåŒ–å Jaccard/å­—ç¬¦è¦†ç›–ç‡ >= 0.9ï¼ˆç®€åŒ–ä¸ºè¦†ç›–ç‡ï¼‰
    """
    if not prev or not curr:
        return False
    p = _norm_for_sim(prev)
    c = _norm_for_sim(curr)
    if not p or not c:
        return False
    if c.startswith(p) and (len(c) - len(p) <= 10):
        return True
    if p.startswith(c) and (len(p) - len(c) <= 10):
        return True
    # è¦†ç›–ç‡
    import collections
    pc = collections.Counter(p)
    cc = collections.Counter(c)
    # è®¡ç®—è¾ƒçŸ­ä¸²è¢«è¾ƒé•¿ä¸²è¦†ç›–æ¯”ä¾‹
    short, longc = (pc, cc) if sum(pc.values()) <= sum(cc.values()) else (cc, pc)
    inter = sum(min(short[k], longc.get(k, 0)) for k in short)
    cov = inter / max(1, sum(short.values()))
    return cov >= 0.9

# ---------- è¡Œå¤„ç†ä¸é¡ºåºæ‰«æï¼ˆåŠ å…¥å»é‡ï¼‰ ----------

def process_row(row: Tuple[int, int, int, bytes]) -> Optional[dict]:
    """
    å¤„ç†ä¸€è¡Œæ•°æ®ï¼Œæå– roleã€content åŠå¯¹ç«¯ peerï¼ˆ40030ï¼‰ï¼›æ— æ•ˆè¿”å› Noneã€‚
    """
    timestamp, sender_30, sender_33, blob_data = row
    if not blob_data:
        return None
    text_content = extract_text_content(blob_data)
    if not text_content:
        return None
    if sender_33 == 1684773595:  # AI
        role = "assistant"
    elif sender_33 == sender_30:  # ç”¨æˆ·/å¥½å‹
        role = "user"
    else:
        return None
    return {"timestamp": timestamp, "peer": sender_30, "role": role, "content": text_content}

def main():
    # è¾“å‡ºæ–‡ä»¶åï¼ˆä¿æŒåŸæœ‰ï¼‰ï¼Œè‡ªåŠ¨ç”Ÿæˆ pretty ç‰ˆæœ¬
    output_file = "training_data.jsonl"
    db = DatabaseConnector(DB_PATH)

    try:
        db.connect()
        print(f"å¼€å§‹ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œè¾“å‡ºåˆ°: {output_file}", file=sys.stderr)

        # è·å–æ‰€æœ‰å”¯ä¸€çš„QQå·ï¼ˆpeerï¼‰
        peers = db.query("SELECT DISTINCT `40030` FROM c2c_msg_table WHERE `40030` IS NOT NULL")
        all_peers = [peer[0] for peer in peers]
        print(f"æ‰¾åˆ° {len(all_peers)} ä¸ªQQå·", file=sys.stderr)

        # åŒæ—¶è¾“å‡ºä¸€ä¸ªä¾¿äºäººå·¥é˜…è¯»çš„å¯è¯»ç‰ˆ
        pretty_output_file = output_file.rsplit('.', 1)[0] + "_pretty.jsonl"
        with open(output_file, 'w', encoding='utf-8', buffering=1024 * 1024) as f, \
             open(pretty_output_file, 'w', encoding='utf-8', buffering=1024 * 1024) as pretty_f:
            
            written_dialogs = 0
            processed = 0

            # å¯¹æ¯ä¸ªQQå·è¿›è¡Œå¤„ç†
            for peer in all_peers:
                print(f"å¤„ç†QQå·: {peer}", file=sys.stderr)
                
                # è·å–è¯¥QQå·çš„æ‰€æœ‰æ¶ˆæ¯
                rows = db.query("""
                    SELECT `40050`, `40030`, `40033`, `40800`
                    FROM c2c_msg_table
                    WHERE `40030` = ? AND `40800` IS NOT NULL
                    ORDER BY `40050` ASC
                """, (peer,))
                
                if not rows:
                    continue

                # æŒ‰æ—¥æœŸåˆ†ç»„çš„æ¶ˆæ¯
                daily_messages = defaultdict(list)
                
                # å¤„ç†è¯¥QQå·çš„æ‰€æœ‰æ¶ˆæ¯
                for (timestamp, sender_30, sender_33, blob_data) in rows:
                    processed += 1
                    
                    res = process_row((timestamp, sender_30, sender_33, blob_data))
                    if res is None:
                        continue
                    
                    # è®¡ç®—UTC+12æ—¶åŒºçš„æ—¥æœŸ
                    utc_time = datetime.datetime.utcfromtimestamp(timestamp)
                    utc_plus_12_time = utc_time + datetime.timedelta(hours=12)
                    message_date = utc_plus_12_time.strftime('%Y-%m-%d')
                    
                    daily_messages[message_date].append(res)

                # å¯¹æ¯ä¸ªæ—¥æœŸç”Ÿæˆä¸€ä¸ªå¯¹è¯
                for date, messages in daily_messages.items():
                    if not messages or len(messages) <= 1:
                        continue
                    
                    # å»é‡å¤„ç†
                    from collections import deque
                    last_by_role = {"user": "", "assistant": ""}
                    recent_window = deque(maxlen=6)
                    
                    def is_recent_duplicate(s: str) -> bool:
                        from collections import Counter
                        ns = _norm_for_sim(s)
                        if not ns:
                            return False
                        for prev in recent_window:
                            p = _norm_for_sim(prev)
                            if not p:
                                continue
                            if ns.startswith(p) and len(ns) - len(p) <= 10:
                                return True
                            if p.startswith(ns) and len(p) - len(ns) <= 10:
                                return True
                            pc = Counter(p); cc = Counter(ns)
                            short, longc = (pc, cc) if sum(pc.values()) <= sum(cc.values()) else (cc, pc)
                            inter = sum(min(short[k], longc.get(k, 0)) for k in short)
                            cov = inter / max(1, sum(short.values()))
                            if cov >= 0.92:
                                return True
                        return False

                    # æ„å»ºè¯¥æ—¥æœŸçš„å¯¹è¯
                    daily_dialog = []
                    for msg in messages:
                        role = msg["role"]
                        content = msg["content"]
                        
                        # å»é‡ï¼šåŒè§’è‰²è¿‘é‡å¤ æˆ– è·¨è§’è‰²çª—å£è¿‘é‡å¤
                        if (last_by_role[role] and is_near_duplicate(last_by_role[role], content)) or is_recent_duplicate(content):
                            continue
                        
                        daily_dialog.append({"role": role, "content": content})
                        last_by_role[role] = content
                        recent_window.append(content)

                    # å†™å…¥è¯¥æ—¥æœŸçš„å¯¹è¯
                    if daily_dialog:
                        flush_dialog(f, daily_dialog, pretty_f)
                        written_dialogs += 1

                if processed % 5000 == 0:
                    print(f"å·²å¤„ç†æ¶ˆæ¯: {processed}ï¼Œå·²å†™å…¥å¯¹è¯æ®µ: {written_dialogs}", file=sys.stderr)

        print(f"å®Œæˆ! å¤„ç† {processed} æ¡æ¶ˆæ¯ï¼Œå†™å‡º {written_dialogs} æ®µå¯¹è¯åˆ° {output_file}", file=sys.stderr)

    except Exception as e:
        print(f"é”™è¯¯: {e}", file=sys.stderr)
    finally:
        db.close()

if __name__ == "__main__":
    main()