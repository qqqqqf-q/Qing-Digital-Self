{
    "repoid": "Qing-Agent",
    "branch": "main",
    "version": "0.1.2",
    "model_path": "./model/Qwen3-8B-Base",
    "model_repo": "Qwen/Qwen-3-8B-Base",
    "model_output_path": "./model_output",
    "template": "qwen",
    "finetuning_type": "qlora",
    "trust_remote_code": true,
    "download_source": "modelscope",
    "log_level": "INFO",
    "language": "zhcn",
    "data_args": {
        "qq_agrs": {
            "qq_db_path": "./dataset/original/qq.db",
            "qq_number_ai": "1684773595"
        },
        "telegram_args": {
            "telegram_chat_id": null
        },
        "include_type": [
            "text"
        ],
        "blocked_words": [
            "密码",
            "账号",
            "手机号"
        ],
        "single_combine_time_window": 2,
        "qa_match_time_window": 5,
        "combine_msg_max_length": 2048,
        "messages_max_length": 2048,
        "clean_set_args": {
            "clean_method": "llm",
            "openai_api": {
                "api_base": "http://127.0.0.1:1236",
                "api_key": "sk-1234567890abcdef1234567890abcdef",
                "model_name": "qwen3-8b-fp6",
                "clean_batch_size": 10,
                "clean_workers": 4,
                "timeout": 20
            }
        },
        "train_sft_args": {
            "use_qlora": true,
            "data_path": "./dataset/sft.jsonl",
            "lora_r": 16,
            "lora_alpha": 32,
            "lora_dropout": 0.1,
            "lora_target_modules": [
                "q_proj",
                "v_proj"
            ],
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 16,
            "max_steps": -1,
            "learning_rate": 0.0002,
            "fp16": true,
            "logging_steps": 10,
            "save_steps": 100,
            "load_precision": "int8"
        },
        "system_prompt": "*"
    },
    "max_workers": 6,
    "use_unsloth": false
}