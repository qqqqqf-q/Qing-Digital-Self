<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>1. Extracting from Dual-Audio Track Video/Audio Files (Requires Separated Audio Tracks) | Qing-Digital-Self</title>
    <meta name="description" content="Qing's digital avatar with complete setup tutorial">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/Qing-Digital-Self/assets/style.saCJ7iHT.css" as="style">
    <link rel="preload stylesheet" href="/Qing-Digital-Self/vp-icons.css" as="style">
    
    <script type="module" src="/Qing-Digital-Self/assets/app.D1rCpgyH.js"></script>
    <link rel="preload" href="/Qing-Digital-Self/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/Qing-Digital-Self/assets/chunks/theme.CB5kl2g0.js">
    <link rel="modulepreload" href="/Qing-Digital-Self/assets/chunks/framework.DUP9kEI5.js">
    <link rel="modulepreload" href="/Qing-Digital-Self/assets/en_guide_media-chat-data.md.8G-QBXri.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-d8b57b2d><!--[--><!--]--><!--[--><span tabindex="-1" data-v-fcbfc0e0></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-fcbfc0e0>Skip to content</a><!--]--><!----><header class="VPNav" data-v-d8b57b2d data-v-7ad780c2><div class="VPNavBar" data-v-7ad780c2 data-v-9fd4d1dd><div class="wrapper" data-v-9fd4d1dd><div class="container" data-v-9fd4d1dd><div class="title" data-v-9fd4d1dd><div class="VPNavBarTitle has-sidebar" data-v-9fd4d1dd data-v-9f43907a><a class="title" href="/Qing-Digital-Self/en/" data-v-9f43907a><!--[--><!--]--><!----><span data-v-9f43907a>Qing-Digital-Self</span><!--[--><!--]--></a></div></div><div class="content" data-v-9fd4d1dd><div class="content-body" data-v-9fd4d1dd><!--[--><!--]--><div class="VPNavBarSearch search" data-v-9fd4d1dd><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-9fd4d1dd data-v-afb2845e><span id="main-nav-aria-label" class="visually-hidden" data-v-afb2845e> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/Qing-Digital-Self/en/" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/Qing-Digital-Self/en/guide/index.html" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>Quick Start</span><!--]--></a><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-9fd4d1dd data-v-acee064b data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="Change language" data-v-bfe7971f><span class="text" data-v-bfe7971f><span class="vpi-languages option-icon" data-v-bfe7971f></span><!----><span class="vpi-chevron-down text-icon" data-v-bfe7971f></span></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><!----><!--[--><!--[--><div class="items" data-v-acee064b><p class="title" data-v-acee064b>English</p><!--[--><div class="VPMenuLink" data-v-acee064b data-v-7eeeb2dc><a class="VPLink link" href="/Qing-Digital-Self/guide/media-chat-data.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>中文</span><!--]--></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-9fd4d1dd data-v-3f90c1a5><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-3f90c1a5 data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-9fd4d1dd data-v-ef6192dc data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/qqqqqf-q/Qing-Digital-Self" aria-label="github" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-9fd4d1dd data-v-f953d92f data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-bfe7971f><span class="vpi-more-horizontal icon" data-v-bfe7971f></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><!----><!--[--><!--[--><div class="group translations" data-v-f953d92f><p class="trans-title" data-v-f953d92f>English</p><!--[--><div class="VPMenuLink" data-v-f953d92f data-v-7eeeb2dc><a class="VPLink link" href="/Qing-Digital-Self/guide/media-chat-data.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>中文</span><!--]--></a></div><!--]--></div><div class="group" data-v-f953d92f><div class="item appearance" data-v-f953d92f><p class="label" data-v-f953d92f>Appearance</p><div class="appearance-action" data-v-f953d92f><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-f953d92f data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div></div></div><div class="group" data-v-f953d92f><div class="item social-links" data-v-f953d92f><div class="VPSocialLinks social-links-list" data-v-f953d92f data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/qqqqqf-q/Qing-Digital-Self" aria-label="github" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-9fd4d1dd data-v-6bee1efd><span class="container" data-v-6bee1efd><span class="top" data-v-6bee1efd></span><span class="middle" data-v-6bee1efd></span><span class="bottom" data-v-6bee1efd></span></span></button></div></div></div></div><div class="divider" data-v-9fd4d1dd><div class="divider-line" data-v-9fd4d1dd></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-d8b57b2d data-v-2488c25a><div class="container" data-v-2488c25a><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-2488c25a><span class="vpi-align-left menu-icon" data-v-2488c25a></span><span class="menu-text" data-v-2488c25a>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-2488c25a data-v-6b867909><button data-v-6b867909>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-d8b57b2d data-v-42c4c606><div class="curtain" data-v-42c4c606></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-42c4c606><span class="visually-hidden" id="sidebar-aria-label" data-v-42c4c606> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>Getting Started</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/index.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Introduction</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0 has-active" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>Quick Start</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/qq-database.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>1. Get QQ Database</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/media-chat-data.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>1.5 (Optional) Get Chat Data from Media</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/clean-data.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>2. Clean Data</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/mix-data.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>3. Mix Data</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/prepare-model.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>4. Prepare Model</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/fine-tune-model.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>5. Fine-tune Model</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/run-full-model.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>6. (Optional) Run Full Model</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/convert-model.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>7. Convert GGUF and Quantize</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/run-model.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>8. Run Model</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/fine-tune-openai-oss-model.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>9. (Extra) Fine-tune OpenAI OSS Model</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>Extra</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/change-logger-language.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Change Logger Language</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/fine-tune-model-exp.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Fine-tuning Experience with Different Models (Qwen, Llama, Gemma, etc.)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/save-vram.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>VRAM Optimization</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>Summary</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/summary.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>9. Summary</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-d8b57b2d data-v-9a6c75ad><div class="VPDoc has-sidebar has-aside" data-v-9a6c75ad data-v-e6f2a212><!--[--><!--]--><div class="container" data-v-e6f2a212><div class="aside" data-v-e6f2a212><div class="aside-curtain" data-v-e6f2a212></div><div class="aside-container" data-v-e6f2a212><div class="aside-content" data-v-e6f2a212><div class="VPDocAside" data-v-e6f2a212 data-v-cb998dce><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-cb998dce data-v-f610f197><div class="content" data-v-f610f197><div class="outline-marker" data-v-f610f197></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-f610f197>On this page</div><ul class="VPDocOutlineItem root" data-v-f610f197 data-v-53c99d69><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-cb998dce></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-e6f2a212><div class="content-container" data-v-e6f2a212><!--[--><!--]--><main class="main" data-v-e6f2a212><div style="position:relative;" class="vp-doc _Qing-Digital-Self_en_guide_media-chat-data" data-v-e6f2a212><div><h2 id="extracting-chat-data-from-media-files" tabindex="-1">Extracting Chat Data from Media Files <a class="header-anchor" href="#extracting-chat-data-from-media-files" aria-label="Permalink to &quot;Extracting Chat Data from Media Files&quot;">​</a></h2><h1 id="_1-extracting-from-dual-audio-track-video-audio-files-requires-separated-audio-tracks" tabindex="-1">1. Extracting from Dual-Audio Track Video/Audio Files (Requires Separated Audio Tracks) <a class="header-anchor" href="#_1-extracting-from-dual-audio-track-video-audio-files-requires-separated-audio-tracks" aria-label="Permalink to &quot;1. Extracting from Dual-Audio Track Video/Audio Files (Requires Separated Audio Tracks)&quot;">​</a></h1><h1 id="video-to-chatml-converter" tabindex="-1">Video to ChatML Converter <a class="header-anchor" href="#video-to-chatml-converter" aria-label="Permalink to &quot;Video to ChatML Converter&quot;">​</a></h1><p>Converts video files containing dual-track conversations into ChatML-format JSON files.</p><h2 id="features" tabindex="-1">Features <a class="header-anchor" href="#features" aria-label="Permalink to &quot;Features&quot;">​</a></h2><ul><li>Supports various video formats (MKV, MP4, etc.)</li><li>Uses OpenAI Whisper for high-quality speech recognition</li><li>CUDA acceleration support (if available)</li><li>Automatically sorts dialogue by timestamp</li><li>Generates standard ChatML output</li></ul><h2 id="quick-start" tabindex="-1">Quick Start <a class="header-anchor" href="#quick-start" aria-label="Permalink to &quot;Quick Start&quot;">​</a></h2><h3 id="_1-install-dependencies" tabindex="-1">1. Install Dependencies <a class="header-anchor" href="#_1-install-dependencies" aria-label="Permalink to &quot;1. Install Dependencies&quot;">​</a></h3><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Automatically install all dependencies</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> start-vtc.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --install</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Or install manually</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> requirements.txt</span></span></code></pre></div><p><strong>Note</strong>: You also need to install ffmpeg:</p><ul><li>Windows: Download from <a href="https://ffmpeg.org" target="_blank" rel="noreferrer">https://ffmpeg.org</a> or use <code>choco install ffmpeg</code></li><li>Ubuntu: <code>sudo apt install ffmpeg</code></li><li>macOS: <code>brew install ffmpeg</code></li></ul><h3 id="_2-usage" tabindex="-1">2. Usage <a class="header-anchor" href="#_2-usage" aria-label="Permalink to &quot;2. Usage&quot;">​</a></h3><h4 id="interactive-mode-recommended-for-new-users" tabindex="-1">Interactive Mode (Recommended for New Users) <a class="header-anchor" href="#interactive-mode-recommended-for-new-users" aria-label="Permalink to &quot;Interactive Mode (Recommended for New Users)&quot;">​</a></h4><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> start-vtc.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -i</span></span></code></pre></div><h4 id="direct-command-line-mode" tabindex="-1">Direct Command-Line Mode <a class="header-anchor" href="#direct-command-line-mode" aria-label="Permalink to &quot;Direct Command-Line Mode&quot;">​</a></h4><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> start-vtc.py</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> video.mp4</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -u</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -a</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -o</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> output.json</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -m</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> base</span></span></code></pre></div><h4 id="using-the-main-program-directly" tabindex="-1">Using the Main Program Directly <a class="header-anchor" href="#using-the-main-program-directly" aria-label="Permalink to &quot;Using the Main Program Directly&quot;">​</a></h4><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> video-to-chatml.py</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> video.mp4</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -u</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -a</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -o</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> output.json</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -m</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> base</span></span></code></pre></div><h2 id="parameter-description" tabindex="-1">Parameter Description <a class="header-anchor" href="#parameter-description" aria-label="Permalink to &quot;Parameter Description&quot;">​</a></h2><ul><li><code>video</code>: Path to the input video file</li><li><code>-u, --user-track</code>: User audio track index (default: 0)</li><li><code>-a, --assistant-track</code>: Assistant audio track index (default: 1)</li><li><code>-o, --output</code>: Output ChatML file path</li><li><code>-m, --model</code>: Whisper model size (tiny/base/small/medium/large, default: base)</li></ul><h2 id="whisper-model-options" tabindex="-1">Whisper Model Options <a class="header-anchor" href="#whisper-model-options" aria-label="Permalink to &quot;Whisper Model Options&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Model</th><th>Parameters</th><th>RAM Usage</th><th>Speed</th><th>Accuracy</th></tr></thead><tbody><tr><td>tiny</td><td>39M</td><td>~1GB</td><td>Fastest</td><td>Lowest</td></tr><tr><td>base</td><td>74M</td><td>~1GB</td><td>Fast</td><td>Low</td></tr><tr><td>small</td><td>244M</td><td>~2GB</td><td>Medium</td><td>Medium</td></tr><tr><td>medium</td><td>769M</td><td>~5GB</td><td>Slow</td><td>High</td></tr><tr><td>large</td><td>1550M</td><td>~10GB</td><td>Slowest</td><td>Highest</td></tr></tbody></table><h2 id="output-format" tabindex="-1">Output Format <a class="header-anchor" href="#output-format" aria-label="Permalink to &quot;Output Format&quot;">​</a></h2><p>The generated ChatML file format looks like this:</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;role&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;user&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;User&#39;s spoken content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;timestamp&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;start&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;end&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2.5</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  },</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;role&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;assistant&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Assistant&#39;s response&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;timestamp&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;start&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;end&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5.0</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span></code></pre></div><h2 id="frequently-asked-questions" tabindex="-1">Frequently Asked Questions <a class="header-anchor" href="#frequently-asked-questions" aria-label="Permalink to &quot;Frequently Asked Questions&quot;">​</a></h2><h3 id="_1-cuda-support" tabindex="-1">1. CUDA Support <a class="header-anchor" href="#_1-cuda-support" aria-label="Permalink to &quot;1. CUDA Support&quot;">​</a></h3><p>If you have an NVIDIA GPU, the program will automatically use CUDA acceleration. Check CUDA support:</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> start-vtc.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --check</span></span></code></pre></div><h3 id="_2-identifying-audio-tracks" tabindex="-1">2. Identifying Audio Tracks <a class="header-anchor" href="#_2-identifying-audio-tracks" aria-label="Permalink to &quot;2. Identifying Audio Tracks&quot;">​</a></h3><p>Use interactive mode to view all audio tracks in the video, which helps select the correct track index.</p><h3 id="_3-out-of-memory" tabindex="-1">3. Out of Memory <a class="header-anchor" href="#_3-out-of-memory" aria-label="Permalink to &quot;3. Out of Memory&quot;">​</a></h3><p>If you run into memory issues, try using a smaller Whisper model (e.g., <code>tiny</code> or <code>base</code>).</p><h2 id="dependencies" tabindex="-1">Dependencies <a class="header-anchor" href="#dependencies" aria-label="Permalink to &quot;Dependencies&quot;">​</a></h2><ul><li>Python 3.7+</li><li>openai-whisper</li><li>torch</li><li>ffmpeg-python</li><li>ffmpeg (system dependency)</li></ul><h2 id="supported-formats" tabindex="-1">Supported Formats <a class="header-anchor" href="#supported-formats" aria-label="Permalink to &quot;Supported Formats&quot;">​</a></h2><p><strong>Video formats</strong>: MP4, MKV, AVI, MOV, WMV, and other ffmpeg-supported formats <strong>Audio codecs</strong>: Most common codecs (AAC, MP3, WAV, etc.)</p><h1 id="_2-todo-automatically-detect-and-extract-from-single-track-video-audio-files-not-implemented-yet" tabindex="-1">2. [TODO] Automatically Detect and Extract from Single-Track Video/Audio Files (Not Implemented Yet) <a class="header-anchor" href="#_2-todo-automatically-detect-and-extract-from-single-track-video-audio-files-not-implemented-yet" aria-label="Permalink to &quot;2. \[TODO] Automatically Detect and Extract from Single-Track Video/Audio Files (Not Implemented Yet)&quot;">​</a></h1></div></div></main><footer class="VPDocFooter" data-v-e6f2a212 data-v-1bcd8184><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-1bcd8184><span class="visually-hidden" id="doc-footer-aria-label" data-v-1bcd8184>Pager</span><div class="pager" data-v-1bcd8184><a class="VPLink link pager-link prev" href="/Qing-Digital-Self/en/guide/qq-database.html" data-v-1bcd8184><!--[--><span class="desc" data-v-1bcd8184>Previous page</span><span class="title" data-v-1bcd8184>1. Get QQ Database</span><!--]--></a></div><div class="pager" data-v-1bcd8184><a class="VPLink link pager-link next" href="/Qing-Digital-Self/en/guide/clean-data.html" data-v-1bcd8184><!--[--><span class="desc" data-v-1bcd8184>Next page</span><span class="title" data-v-1bcd8184>2. Clean Data</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"en_guide_change-logger-language.md\":\"V3sO9rI4\",\"en_guide_clean-data.md\":\"C4CDdYYt\",\"en_guide_convert-model.md\":\"Ct8-b_O3\",\"en_guide_fine-tune-model-exp.md\":\"DJj3sgLC\",\"en_guide_fine-tune-model.md\":\"CL4KBbFZ\",\"en_guide_fine-tune-openai-oss-model.md\":\"CIddW3Vr\",\"en_guide_index.md\":\"BQ4yLQQq\",\"en_guide_media-chat-data.md\":\"8G-QBXri\",\"en_guide_mix-data.md\":\"Duh6ipG9\",\"en_guide_prepare-model.md\":\"CSsG3o9J\",\"en_guide_qq-database.md\":\"DFrcLxh1\",\"en_guide_run-full-model.md\":\"BSMoeFhI\",\"en_guide_run-model.md\":\"CZKmmO5P\",\"en_guide_save-vram.md\":\"CZln7i03\",\"en_guide_summary.md\":\"BIaaPlkD\",\"en_index.md\":\"CyFE1DKx\",\"guide_change-logger-language.md\":\"CpOF6gL7\",\"guide_clean-data.md\":\"BMcoa7ZI\",\"guide_convert-model.md\":\"yD3VhmRz\",\"guide_fine-tune-model-exp.md\":\"BosNsuHj\",\"guide_fine-tune-model.md\":\"C8MyzAOq\",\"guide_fine-tune-openai-oss-model.md\":\"BSAueuo2\",\"guide_index.md\":\"C3Gu0yzv\",\"guide_media-chat-data.md\":\"CbL7cPQu\",\"guide_mix-data.md\":\"p7edc1mo\",\"guide_prepare-model.md\":\"Cr3orsHf\",\"guide_qq-database.md\":\"BBBXO8Jl\",\"guide_run-full-model.md\":\"BUFp91Z2\",\"guide_run-model.md\":\"PCe7hpah\",\"guide_save-vram.md\":\"CoXg1WGx\",\"guide_summary.md\":\"BcXDteQC\",\"index.md\":\"CZbyuoYB\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"VitePress\",\"description\":\"A VitePress site\",\"base\":\"/Qing-Digital-Self/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/qqqqqf-q/Qing-Digital-Self\"}]},\"locales\":{\"root\":{\"label\":\"中文\",\"lang\":\"zh-CN\",\"title\":\"Qing-Digital-Self\",\"description\":\"清凤的数字分身,并且包含了搭建教程\",\"themeConfig\":{\"nav\":[{\"text\":\"开始\",\"link\":\"/\"},{\"text\":\"快速上手\",\"link\":\"/guide/index\"}],\"sidebar\":[{\"text\":\"开始\",\"items\":[{\"text\":\"简介\",\"link\":\"/guide/index\"}]},{\"text\":\"快速上手\",\"items\":[{\"text\":\"1. QQ数据库的获取\",\"link\":\"/guide/qq-database\"},{\"text\":\"1.5 (可选) 从视频/音频文件中获取聊天数据\",\"link\":\"/guide/media-chat-data\"},{\"text\":\"2. 清洗数据\",\"link\":\"/guide/clean-data\"},{\"text\":\"3. 混合数据\",\"link\":\"/guide/mix-data\"},{\"text\":\"4. 准备模型\",\"link\":\"/guide/prepare-model\"},{\"text\":\"5. 微调模型\",\"link\":\"/guide/fine-tune-model\"},{\"text\":\"6. (建议跳过)微调后直接运行全量模型\",\"link\":\"/guide/run-full-model\"},{\"text\":\"7. 转换GUFF和量化模型\",\"link\":\"/guide/convert-model\"},{\"text\":\"8. 运行模型\",\"link\":\"/guide/run-model\"}]},{\"text\":\"补充\",\"items\":[{\"text\":\"修改Logger的语言\",\"link\":\"/guide/change-logger-language\"},{\"text\":\"微调OpenAI OSS模型\",\"link\":\"/guide/fine-tune-openai-oss-model\"},{\"text\":\"不同种类模型的微调经验(例如Qwen,Llama,Gemma等)\",\"link\":\"/guide/fine-tune-model-exp\"},{\"text\":\"节省显存\",\"link\":\"/guide/save-vram\"}]},{\"text\":\"总结\",\"items\":[{\"text\":\"9. 总结\",\"link\":\"/guide/summary\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/qqqqqf-q/Qing-Digital-Self\"}]}},\"en\":{\"label\":\"English\",\"lang\":\"en-US\",\"title\":\"Qing-Digital-Self\",\"description\":\"Qing's digital avatar with complete setup tutorial\",\"themeConfig\":{\"nav\":[{\"text\":\"Home\",\"link\":\"/en/\"},{\"text\":\"Quick Start\",\"link\":\"/en/guide/index\"}],\"sidebar\":[{\"text\":\"Getting Started\",\"items\":[{\"text\":\"Introduction\",\"link\":\"/en/guide/index\"}]},{\"text\":\"Quick Start\",\"items\":[{\"text\":\"1. Get QQ Database\",\"link\":\"/en/guide/qq-database\"},{\"text\":\"1.5 (Optional) Get Chat Data from Media\",\"link\":\"/en/guide/media-chat-data\"},{\"text\":\"2. Clean Data\",\"link\":\"/en/guide/clean-data\"},{\"text\":\"3. Mix Data\",\"link\":\"/en/guide/mix-data\"},{\"text\":\"4. Prepare Model\",\"link\":\"/en/guide/prepare-model\"},{\"text\":\"5. Fine-tune Model\",\"link\":\"/en/guide/fine-tune-model\"},{\"text\":\"6. (Optional) Run Full Model\",\"link\":\"/en/guide/run-full-model\"},{\"text\":\"7. Convert GGUF and Quantize\",\"link\":\"/en/guide/convert-model\"},{\"text\":\"8. Run Model\",\"link\":\"/en/guide/run-model\"},{\"text\":\"9. (Extra) Fine-tune OpenAI OSS Model\",\"link\":\"/en/guide/fine-tune-openai-oss-model\"}]},{\"text\":\"Extra\",\"items\":[{\"text\":\"Change Logger Language\",\"link\":\"/en/guide/change-logger-language\"},{\"text\":\"Fine-tuning Experience with Different Models (Qwen, Llama, Gemma, etc.)\",\"link\":\"/en/guide/fine-tune-model-exp\"},{\"text\":\"VRAM Optimization\",\"link\":\"/en/guide/save-vram\"}]},{\"text\":\"Summary\",\"items\":[{\"text\":\"9. Summary\",\"link\":\"/en/guide/summary\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/qqqqqf-q/Qing-Digital-Self\"}]}}},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>