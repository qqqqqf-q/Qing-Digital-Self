<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Qing-Digital-Self</title>
    <meta name="description" content="Qing's digital avatar with complete setup tutorial">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/Qing-Digital-Self/assets/style.saCJ7iHT.css" as="style">
    <link rel="preload stylesheet" href="/Qing-Digital-Self/vp-icons.css" as="style">
    
    <script type="module" src="/Qing-Digital-Self/assets/app.D1rCpgyH.js"></script>
    <link rel="preload" href="/Qing-Digital-Self/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/Qing-Digital-Self/assets/chunks/theme.CB5kl2g0.js">
    <link rel="modulepreload" href="/Qing-Digital-Self/assets/chunks/framework.DUP9kEI5.js">
    <link rel="modulepreload" href="/Qing-Digital-Self/assets/en_guide_clean-data.md.C4CDdYYt.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-d8b57b2d><!--[--><!--]--><!--[--><span tabindex="-1" data-v-fcbfc0e0></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-fcbfc0e0>Skip to content</a><!--]--><!----><header class="VPNav" data-v-d8b57b2d data-v-7ad780c2><div class="VPNavBar" data-v-7ad780c2 data-v-9fd4d1dd><div class="wrapper" data-v-9fd4d1dd><div class="container" data-v-9fd4d1dd><div class="title" data-v-9fd4d1dd><div class="VPNavBarTitle has-sidebar" data-v-9fd4d1dd data-v-9f43907a><a class="title" href="/Qing-Digital-Self/en/" data-v-9f43907a><!--[--><!--]--><!----><span data-v-9f43907a>Qing-Digital-Self</span><!--[--><!--]--></a></div></div><div class="content" data-v-9fd4d1dd><div class="content-body" data-v-9fd4d1dd><!--[--><!--]--><div class="VPNavBarSearch search" data-v-9fd4d1dd><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-9fd4d1dd data-v-afb2845e><span id="main-nav-aria-label" class="visually-hidden" data-v-afb2845e> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/Qing-Digital-Self/en/" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/Qing-Digital-Self/en/guide/index.html" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>Quick Start</span><!--]--></a><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-9fd4d1dd data-v-acee064b data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="Change language" data-v-bfe7971f><span class="text" data-v-bfe7971f><span class="vpi-languages option-icon" data-v-bfe7971f></span><!----><span class="vpi-chevron-down text-icon" data-v-bfe7971f></span></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><!----><!--[--><!--[--><div class="items" data-v-acee064b><p class="title" data-v-acee064b>English</p><!--[--><div class="VPMenuLink" data-v-acee064b data-v-7eeeb2dc><a class="VPLink link" href="/Qing-Digital-Self/guide/clean-data.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>中文</span><!--]--></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-9fd4d1dd data-v-3f90c1a5><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-3f90c1a5 data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-9fd4d1dd data-v-ef6192dc data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/qqqqqf-q/Qing-Digital-Self" aria-label="github" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-9fd4d1dd data-v-f953d92f data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-bfe7971f><span class="vpi-more-horizontal icon" data-v-bfe7971f></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><!----><!--[--><!--[--><div class="group translations" data-v-f953d92f><p class="trans-title" data-v-f953d92f>English</p><!--[--><div class="VPMenuLink" data-v-f953d92f data-v-7eeeb2dc><a class="VPLink link" href="/Qing-Digital-Self/guide/clean-data.html" data-v-7eeeb2dc><!--[--><span data-v-7eeeb2dc>中文</span><!--]--></a></div><!--]--></div><div class="group" data-v-f953d92f><div class="item appearance" data-v-f953d92f><p class="label" data-v-f953d92f>Appearance</p><div class="appearance-action" data-v-f953d92f><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-f953d92f data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div></div></div><div class="group" data-v-f953d92f><div class="item social-links" data-v-f953d92f><div class="VPSocialLinks social-links-list" data-v-f953d92f data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/qqqqqf-q/Qing-Digital-Self" aria-label="github" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-9fd4d1dd data-v-6bee1efd><span class="container" data-v-6bee1efd><span class="top" data-v-6bee1efd></span><span class="middle" data-v-6bee1efd></span><span class="bottom" data-v-6bee1efd></span></span></button></div></div></div></div><div class="divider" data-v-9fd4d1dd><div class="divider-line" data-v-9fd4d1dd></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-d8b57b2d data-v-2488c25a><div class="container" data-v-2488c25a><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-2488c25a><span class="vpi-align-left menu-icon" data-v-2488c25a></span><span class="menu-text" data-v-2488c25a>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-2488c25a data-v-6b867909><button data-v-6b867909>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-d8b57b2d data-v-42c4c606><div class="curtain" data-v-42c4c606></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-42c4c606><span class="visually-hidden" id="sidebar-aria-label" data-v-42c4c606> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>Getting Started</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/index.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Introduction</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0 has-active" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>Quick Start</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/qq-database.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>1. Get QQ Database</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/media-chat-data.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>1.5 (Optional) Get Chat Data from Media</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/clean-data.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>2. Clean Data</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/mix-data.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>3. Mix Data</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/prepare-model.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>4. Prepare Model</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/fine-tune-model.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>5. Fine-tune Model</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/run-full-model.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>6. (Optional) Run Full Model</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/convert-model.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>7. Convert GGUF and Quantize</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/run-model.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>8. Run Model</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/fine-tune-openai-oss-model.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>9. (Extra) Fine-tune OpenAI OSS Model</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>Extra</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/change-logger-language.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Change Logger Language</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/fine-tune-model-exp.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Fine-tuning Experience with Different Models (Qwen, Llama, Gemma, etc.)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/save-vram.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>VRAM Optimization</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>Summary</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/Qing-Digital-Self/en/guide/summary.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>9. Summary</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-d8b57b2d data-v-9a6c75ad><div class="VPDoc has-sidebar has-aside" data-v-9a6c75ad data-v-e6f2a212><!--[--><!--]--><div class="container" data-v-e6f2a212><div class="aside" data-v-e6f2a212><div class="aside-curtain" data-v-e6f2a212></div><div class="aside-container" data-v-e6f2a212><div class="aside-content" data-v-e6f2a212><div class="VPDocAside" data-v-e6f2a212 data-v-cb998dce><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-cb998dce data-v-f610f197><div class="content" data-v-f610f197><div class="outline-marker" data-v-f610f197></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-f610f197>On this page</div><ul class="VPDocOutlineItem root" data-v-f610f197 data-v-53c99d69><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-cb998dce></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-e6f2a212><div class="content-container" data-v-e6f2a212><!--[--><!--]--><main class="main" data-v-e6f2a212><div style="position:relative;" class="vp-doc _Qing-Digital-Self_en_guide_clean-data" data-v-e6f2a212><div><h2 id="_2-1-clean-data-regular-version-llm-cleaning-version-in-next-chapter" tabindex="-1">2.1 Clean Data (Regular Version, LLM cleaning version in next chapter) <a class="header-anchor" href="#_2-1-clean-data-regular-version-llm-cleaning-version-in-next-chapter" aria-label="Permalink to &quot;2.1 Clean Data (Regular Version, LLM cleaning version in next chapter)&quot;">​</a></h2><blockquote><p>This method is much faster than LLM cleaning, 300k messages done in half a minute But correspondingly the quality is also lower This part is recommended to be optimized on Windows first, then uploaded to GPU server Not sure if there are compatibility issues on Linux</p></blockquote><ul><li><p>Modify the database path and related parameters in the <code>.env</code> file (please note the required fields)</p></li><li><p>Run the cleaning script:</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> generate_training_data.py</span></span></code></pre></div></li></ul><h2 id="_2-2-clean-data-llm-cleaning" tabindex="-1">2.2 Clean Data (LLM Cleaning) <a class="header-anchor" href="#_2-2-clean-data-llm-cleaning" aria-label="Permalink to &quot;2.2 Clean Data (LLM Cleaning)&quot;">​</a></h2><blockquote><p>Need to configure an OpenAI-compatible API For example: LM Studio or vLLM (faster, but more complicated to set up, requires Linux environment)</p></blockquote><blockquote><p>This part is also recommended to be optimized on Windows first, then uploaded to GPU server Not sure if there are compatibility issues on Linux</p></blockquote><h2 id="lm-studio-setup-tutorial" tabindex="-1">LM Studio Setup Tutorial <a class="header-anchor" href="#lm-studio-setup-tutorial" aria-label="Permalink to &quot;LM Studio Setup Tutorial&quot;">​</a></h2><ul><li><ol><li>Go to <a href="https://lmstudio.ai/" target="_blank" rel="noreferrer">LM Studio</a> to download LM Studio</li></ol></li><li><ol start="2"><li>Install LM Studio</li></ol></li><li><ol start="3"><li>Open LM Studio, click <code>Search</code> -&gt; <code>Model Search</code> on the left</li></ol></li><li><ol start="4"><li>Search for <code>qwen3 8b</code> -&gt; <code>Complete Download</code></li></ol></li><li><ol start="5"><li>Choose a quantization version suitable for you <strong>recommend at least Q4, preferably Q6-Q8, depends on your device situation, ask AI if you don&#39;t know</strong></li></ol></li><li>Remember your <strong>model name</strong>, fill it in the <code>Openai_model</code> field in the <code>.env</code> file</li><li>If you don&#39;t know your model name, you can run test_openai.py, it will output all model names</li><li><ol start="6"><li>After installation, click the button next to <code>Status:Stopped</code> in the left <code>Developer</code> section</li></ol></li><li>If the log below shows port occupied, please click <code>settings</code> to change the <code>server port</code></li><li>Remember this <code>server port</code>, fill your configuration in the <code>.env</code> file</li></ul><h3 id="run" tabindex="-1">run! <a class="header-anchor" href="#run" aria-label="Permalink to &quot;run!&quot;">​</a></h3><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> generate_training_data_llm.py</span></span></code></pre></div><blockquote><p>If you encounter 400 error, it&#39;s most likely because the message is too large and was rejected by the model framework</p></blockquote><hr><h2 id="vllm-setup" tabindex="-1">vLLM Setup <a class="header-anchor" href="#vllm-setup" aria-label="Permalink to &quot;vLLM Setup&quot;">​</a></h2><blockquote><p>vLLM requires Linux environment! If your graphics card is decent (&gt;6800xt, &gt;3080) You can choose to use LM Studio, just wait a bit longer, and you can also play with the model The downside is that LM Studio cannot run HF models, and concurrency is terrible</p></blockquote><blockquote><p>vLLM consumes much more VRAM than LM Studio! LM Studio can run 8b_q6 but vLLM can only run 4b_Q6</p></blockquote><blockquote><p>However, the improvement in concurrency efficiency is real</p></blockquote><blockquote><p>But! The context is very short, if there are more than 500 messages in a day, it cannot handle them</p></blockquote><blockquote><p>RTX 3080 tested with 4b_q6 processing, the final jsonl rate is approximately <strong>300kb/minute</strong></p></blockquote><ul><li>Follow these steps to set up:</li></ul><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> apt</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> update</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> apt</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> python3.10-venv</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> git</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -y</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python3</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -m</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> venv</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> vllm_env</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">source</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> vllm_env/bin/activate</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -U</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> pip</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> torch</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --index-url</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> https://download.pytorch.org/whl/cu121</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # If you use CUDA</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> vllm</span></span></code></pre></div><h3 id="different-considerations-from-lm-studio" tabindex="-1">Different considerations from LM Studio <a class="header-anchor" href="#different-considerations-from-lm-studio" aria-label="Permalink to &quot;Different considerations from LM Studio&quot;">​</a></h3><ul><li><ol><li>The <code>Openai_model</code> in <code>.env</code> needs to be set to a path rather than just a folder name</li></ol></li></ul><blockquote><p>It should be <code>/home/vllm/qwen3-4b-int8</code> instead of <code>qwen3-4b-int8</code></p></blockquote><ul><li><ol start="2"><li>The <strong>api_server</strong> to run is <code>vllm.entrypoints.openai.api_server</code> not <code>vllm.entrypoints.api_server</code>, because the second one is not compatible with OpenAI API</li></ol></li></ul><h3 id="example-run-command" tabindex="-1">Example run command <a class="header-anchor" href="#example-run-command" aria-label="Permalink to &quot;Example run command&quot;">​</a></h3><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python3</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -m</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> vllm.entrypoints.openai.api_server</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --model</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /home/vllm/qwen3-4b-int8</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --gpu-memory-utilization</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.7</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --max-model-len</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 10240</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --max-num-seqs</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 4</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --max-num-batched-tokens</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2048</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --dtype</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> auto</span></span></code></pre></div><blockquote><p>If you encounter 400 error, it&#39;s most likely because the message is too large and was rejected by the model framework</p></blockquote></div></div></main><footer class="VPDocFooter" data-v-e6f2a212 data-v-1bcd8184><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-1bcd8184><span class="visually-hidden" id="doc-footer-aria-label" data-v-1bcd8184>Pager</span><div class="pager" data-v-1bcd8184><a class="VPLink link pager-link prev" href="/Qing-Digital-Self/en/guide/media-chat-data.html" data-v-1bcd8184><!--[--><span class="desc" data-v-1bcd8184>Previous page</span><span class="title" data-v-1bcd8184>1.5 (Optional) Get Chat Data from Media</span><!--]--></a></div><div class="pager" data-v-1bcd8184><a class="VPLink link pager-link next" href="/Qing-Digital-Self/en/guide/mix-data.html" data-v-1bcd8184><!--[--><span class="desc" data-v-1bcd8184>Next page</span><span class="title" data-v-1bcd8184>3. Mix Data</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"en_guide_change-logger-language.md\":\"V3sO9rI4\",\"en_guide_clean-data.md\":\"C4CDdYYt\",\"en_guide_convert-model.md\":\"Ct8-b_O3\",\"en_guide_fine-tune-model-exp.md\":\"DJj3sgLC\",\"en_guide_fine-tune-model.md\":\"CL4KBbFZ\",\"en_guide_fine-tune-openai-oss-model.md\":\"gSinuAES\",\"en_guide_index.md\":\"BQ4yLQQq\",\"en_guide_media-chat-data.md\":\"8G-QBXri\",\"en_guide_mix-data.md\":\"Duh6ipG9\",\"en_guide_prepare-model.md\":\"CSsG3o9J\",\"en_guide_qq-database.md\":\"DFrcLxh1\",\"en_guide_run-full-model.md\":\"BSMoeFhI\",\"en_guide_run-model.md\":\"CZKmmO5P\",\"en_guide_save-vram.md\":\"CZln7i03\",\"en_guide_summary.md\":\"BIaaPlkD\",\"en_index.md\":\"CyFE1DKx\",\"guide_change-logger-language.md\":\"CpOF6gL7\",\"guide_clean-data.md\":\"BMcoa7ZI\",\"guide_convert-model.md\":\"yD3VhmRz\",\"guide_fine-tune-model-exp.md\":\"BosNsuHj\",\"guide_fine-tune-model.md\":\"C8MyzAOq\",\"guide_fine-tune-openai-oss-model.md\":\"BCWoxzP0\",\"guide_index.md\":\"C3Gu0yzv\",\"guide_media-chat-data.md\":\"CbL7cPQu\",\"guide_mix-data.md\":\"BZrBzsqS\",\"guide_prepare-model.md\":\"Cr3orsHf\",\"guide_qq-database.md\":\"BBBXO8Jl\",\"guide_run-full-model.md\":\"BUFp91Z2\",\"guide_run-model.md\":\"PCe7hpah\",\"guide_save-vram.md\":\"CoXg1WGx\",\"guide_summary.md\":\"BcXDteQC\",\"index.md\":\"CZbyuoYB\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"VitePress\",\"description\":\"A VitePress site\",\"base\":\"/Qing-Digital-Self/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/qqqqqf-q/Qing-Digital-Self\"}]},\"locales\":{\"root\":{\"label\":\"中文\",\"lang\":\"zh-CN\",\"title\":\"Qing-Digital-Self\",\"description\":\"清凤的数字分身,并且包含了搭建教程\",\"themeConfig\":{\"nav\":[{\"text\":\"开始\",\"link\":\"/\"},{\"text\":\"快速上手\",\"link\":\"/guide/index\"}],\"sidebar\":[{\"text\":\"开始\",\"items\":[{\"text\":\"简介\",\"link\":\"/guide/index\"}]},{\"text\":\"快速上手\",\"items\":[{\"text\":\"1. QQ数据库的获取\",\"link\":\"/guide/qq-database\"},{\"text\":\"1.5 (可选) 从视频/音频文件中获取聊天数据\",\"link\":\"/guide/media-chat-data\"},{\"text\":\"2. 清洗数据\",\"link\":\"/guide/clean-data\"},{\"text\":\"3. 混合数据\",\"link\":\"/guide/mix-data\"},{\"text\":\"4. 准备模型\",\"link\":\"/guide/prepare-model\"},{\"text\":\"5. 微调模型\",\"link\":\"/guide/fine-tune-model\"},{\"text\":\"6. (建议跳过)微调后直接运行全量模型\",\"link\":\"/guide/run-full-model\"},{\"text\":\"7. 转换GUFF和量化模型\",\"link\":\"/guide/convert-model\"},{\"text\":\"8. 运行模型\",\"link\":\"/guide/run-model\"}]},{\"text\":\"补充\",\"items\":[{\"text\":\"修改Logger的语言\",\"link\":\"/guide/change-logger-language\"},{\"text\":\"微调OpenAI OSS模型\",\"link\":\"/guide/fine-tune-openai-oss-model\"},{\"text\":\"不同种类模型的微调经验(例如Qwen,Llama,Gemma等)\",\"link\":\"/guide/fine-tune-model-exp\"},{\"text\":\"节省显存\",\"link\":\"/guide/save-vram\"}]},{\"text\":\"总结\",\"items\":[{\"text\":\"9. 总结\",\"link\":\"/guide/summary\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/qqqqqf-q/Qing-Digital-Self\"}]}},\"en\":{\"label\":\"English\",\"lang\":\"en-US\",\"title\":\"Qing-Digital-Self\",\"description\":\"Qing's digital avatar with complete setup tutorial\",\"themeConfig\":{\"nav\":[{\"text\":\"Home\",\"link\":\"/en/\"},{\"text\":\"Quick Start\",\"link\":\"/en/guide/index\"}],\"sidebar\":[{\"text\":\"Getting Started\",\"items\":[{\"text\":\"Introduction\",\"link\":\"/en/guide/index\"}]},{\"text\":\"Quick Start\",\"items\":[{\"text\":\"1. Get QQ Database\",\"link\":\"/en/guide/qq-database\"},{\"text\":\"1.5 (Optional) Get Chat Data from Media\",\"link\":\"/en/guide/media-chat-data\"},{\"text\":\"2. Clean Data\",\"link\":\"/en/guide/clean-data\"},{\"text\":\"3. Mix Data\",\"link\":\"/en/guide/mix-data\"},{\"text\":\"4. Prepare Model\",\"link\":\"/en/guide/prepare-model\"},{\"text\":\"5. Fine-tune Model\",\"link\":\"/en/guide/fine-tune-model\"},{\"text\":\"6. (Optional) Run Full Model\",\"link\":\"/en/guide/run-full-model\"},{\"text\":\"7. Convert GGUF and Quantize\",\"link\":\"/en/guide/convert-model\"},{\"text\":\"8. Run Model\",\"link\":\"/en/guide/run-model\"},{\"text\":\"9. (Extra) Fine-tune OpenAI OSS Model\",\"link\":\"/en/guide/fine-tune-openai-oss-model\"}]},{\"text\":\"Extra\",\"items\":[{\"text\":\"Change Logger Language\",\"link\":\"/en/guide/change-logger-language\"},{\"text\":\"Fine-tuning Experience with Different Models (Qwen, Llama, Gemma, etc.)\",\"link\":\"/en/guide/fine-tune-model-exp\"},{\"text\":\"VRAM Optimization\",\"link\":\"/en/guide/save-vram\"}]},{\"text\":\"Summary\",\"items\":[{\"text\":\"9. Summary\",\"link\":\"/en/guide/summary\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/qqqqqf-q/Qing-Digital-Self\"}]}}},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>