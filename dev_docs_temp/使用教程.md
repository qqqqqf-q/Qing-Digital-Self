注:
CLI并不完全可用
有些功能还没实现
除了标注无法使用的均已测试

获取qq数据库
https://qqqqqf-q.github.io/Qing-Digital-Self/guide/qq-database.html
放到dataset/originl/qq.db下
(默认就是dataset/original/qq.db,不需要修改seeting.jsonc)

首先
git clone https://github.com/qqqqqf-q/Qing-Digital-Self.git --depth 1
或者
git clone https://hk.gh-proxy.com/https://github.com/qqqqqf-q/Qing-Digital-Self.git  --depth 1
国内加速用
然后
'''bash
python33 environment/setup_env.py --install 
或者
python3 environment/setup_env.py --install 
'''
若是cuda,则选择1
若有其他安装,请选择2
选3则跳过

默认跟着流程走就好
安装完自带检查
也可以使用
```bash
python3 environment/setup_env.py --check
``` 
来进行检查环境
如果遇到unsloth无法安装请自行安装
先运行以下命令
'''bash
wget -qO- https://raw.githubusercontent.com/unslothai/unsloth/main/unsloth/_auto_install.py | python -
'''
它会输出一个pip命令,请复制下来并在shell里运行 例如

'''bash
pip install --upgrade pip && pip install "unsloth[cu126-ampere-torch270] @ git+https://github.com/unslothai/unsloth.git"
'''
如果遇到flah attn安装问题
可以尝试前往
https://github.com/Dao-AILab/flash-attention/releases/
来查看你需要的离线安装包(这个不需要编译,会快非常多)
命令类似:
'''bash
wget https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.3/flash_attn-2.8.3+cu12torch2.4cxx11abiTRUE-cp312-cp312-linux_x86_64.whl'

pip install flash_attn-2.8.3+cu12torch2.4cxx11abiTRUE-cp312-cp312-linux_x86_64.whl
'''



然后
'''bash 
source "./qds_env/bin/activate"
’‘’
windows下
'''bash
& "./qds_env/Scripts/Activate.ps1"

'''




随后:
'''bash
python3 cli.py config init
'''
随后请使用编辑器修改setting.jsonc或使用
'''bash
python3 cli.py config set <key> <value>
'''
来设置对应config的值
```bash
# 初始化配置文件
python3 cli.py config init

# 交互式配置向导
python3 cli.py config init --interactive

# 显示当前配置
python3 cli.py config show

# 以JSON格式显示配置
python3 cli.py config show --format json

# 设置配置项
python3 cli.py config set log_level DEBUG

# 验证配置
python3 cli.py config validate
```

在设置完模型参数后可以使用这个下载模型
支持从ModelScope和HuggingFace下载模型：

```bash
# 使用配置文件中的设置
python3 environment/download/model_download.py

# 指定参数下载
python3 environment/download/model_download.py \
  --model-repo Qwen/Qwen-3-8B-Base \
  --model-path ./model/Qwen-3-8B-Base \
  --download-source modelscope
 #download-source 可选modelscope或者huggingface
# 列出已下载的模型
python3 environment/download/model_download.py --list

# 查看模型信息
python3 environment/download/model_download.py --info ./model/Qwen2.5-7B-Instruct
```
### 数据处理

```bash

均会自动从conig获取字段,parser仅作为额外使用
# 从QQ数据库提取数据
python3 cli.py data extract
python3 cli.py data extract --qq-db-path ./data/qq.db --qq-number-ai 1684773595 --output ./dataset/csv

# 清洗数据（原始算法）
python3 cli.py data clean raw

# 清洗数据（LLM方法,为实现,暂时等同于raw）
python3 cli.py data clean llm  #内容会在这一步转成为chatml格式

# 合并多源数据
python3 cli.py data merge --inputs ./data/file1.jsonl ./data/file2.jsonl --output ./data/merged.jsonl --deduplicate
# 这一项并没有进行测试,不一定能跑

# 预览数据
python3 cli.py data preview --input ./dataset/sft.jsonl --count 3

# 数据统计
python3 cli.py data stats --input ./dataset/sft.jsonl
```

### 模型训练

> 没有进行完整测试  
```bash
# 开始训练
python3 cli.py train start

# 高级训练参数
python3 cli.py train start \
  --model-path ./model/Qwen3-8B \
  --data-path ./data/training.jsonl \
  --output-dir ./checkpoints \
  --lora-r 16 \
  --lora-alpha 32 \
  --batch-size 1 \
  --max-steps 1000

# 恢复训练
python3 cli.py train start --resume ./checkpoints/checkpoint-500

# 查看训练状态
python3 cli.py train status

# 实时跟踪训练日志
python3 cli.py train status --follow

# 停止训练
python3 cli.py train stop

# 强制停止训练
python3 cli.py train stop --force

# 合并LoRA权重
python3 cli.py train merge --base-model ./model/Qwen3-8B --lora-path ./checkpoints/final --output ./model/merged
```

还有基础部分
### 基本使用

```bash
# 查看帮助
python3 cli.py --help

# 查看版本
python3 cli.py --version

# 详细输出模式
python3 cli.py --verbose <command>

# 静默模式
python3 cli.py --quiet <command>
```

还有一些功能AI已经写出来了,但是我可能会删掉一些函数或重写
AI原稿在cli_使用说明和env_readme

generate_training_data暂时留着作为llm清洗功能,后期会重写或者删掉