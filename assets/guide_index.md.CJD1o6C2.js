import{_ as i,c as l,o as a,ae as t}from"./chunks/framework.DUP9kEI5.js";const p=JSON.parse('{"title":"V 0.1.1(MVP)","description":"","frontmatter":{},"headers":[],"relativePath":"guide/index.md","filePath":"guide/index.md"}'),o={name:"guide/index.md"};function r(s,e,n,h,d,c){return a(),l("div",null,e[0]||(e[0]=[t('<h2 id="项目简介" tabindex="-1">项目简介 <a class="header-anchor" href="#项目简介" aria-label="Permalink to &quot;项目简介&quot;">​</a></h2><h2 id="这是一个数字分身项目-核心思想是利用-qq-的-c2c-聊天记录作为数据集-对大模型进行微调-让模型尽可能还原你独有的表达风格和聊天方式。" tabindex="-1">这是一个数字分身项目，核心思想是<strong>利用 QQ 的 C2C 聊天记录作为数据集，对大模型进行微调</strong>，让模型尽可能还原你独有的表达风格和聊天方式。 <a class="header-anchor" href="#这是一个数字分身项目-核心思想是利用-qq-的-c2c-聊天记录作为数据集-对大模型进行微调-让模型尽可能还原你独有的表达风格和聊天方式。" aria-label="Permalink to &quot;这是一个数字分身项目，核心思想是**利用 QQ 的 C2C 聊天记录作为数据集，对大模型进行微调**，让模型尽可能还原你独有的表达风格和聊天方式。&quot;">​</a></h2><p align="center"><img src="https://img.shields.io/badge/Downloads-1-00bfff?style=for-the-badge" style="display:inline-block;margin-right:8px;"><img src="https://img.shields.io/github/stars/qqqqqf-q/Qing-Digital-Self?style=for-the-badge&amp;color=ff69b4" style="display:inline-block;margin-right:8px;"><img src="https://img.shields.io/badge/Status-MVP-ff69b4?style=for-the-badge" style="display:inline-block;margin-right:8px;"><img src="https://img.shields.io/badge/Version-v0.1.1-9370DB?style=for-the-badge" style="display:inline-block;margin-right:8px;"><img src="https://img.shields.io/github/license/qqqqqf-q/Qing-Digital-Self?style=for-the-badge&amp;color=8A2BE2" style="display:inline-block;"></p><h2 id="项目包含了完整的教程-包括" tabindex="-1">项目包含了<strong>完整的教程</strong>，包括： <a class="header-anchor" href="#项目包含了完整的教程-包括" aria-label="Permalink to &quot;项目包含了**完整的教程**，包括：&quot;">​</a></h2><ul><li>QQ 数据库的解密与处理</li><li>聊天数据清洗与转换</li><li>QLora 微调流程</li><li>微调模型的测试与使用</li><li>使用unsloth加速训练!</li></ul><p>我知道类似的项目其实已经有不少了，但也许我的教程、流程、代码实现能给你一些不一样的帮助或启发。如果对你有用，欢迎点个 star，我会很开心的！</p><p>目前这个项目还有很多不足：</p><ul><li>暂时不知道有什么不足</li><li>(如果有问题欢迎开Issues)</li><li>但已经可以在 4090 24G 显卡上用 fp8 精度微调 Qwen3-8B（亲测可用）</li></ul><p><strong>如果你也想打造属于自己的数字分身，那也来试试吧!</strong></p><p>—— X: <a href="https://twitter.com/qqqqqf5" target="_blank" rel="noreferrer">@qqqqqf5</a></p><hr><a href="https://qqqqqf-q.github.io/Qing-Digital-Self/"><img src="https://cdn.nodeimage.com/i/MfTsvmkJD2dQj9c9XZg9XXXS6CYwZBvx.png" alt="快速开始按钮" width="140" style="margin-top:1em;"></a><hr><h2 id="项目版本" tabindex="-1">项目版本 <a class="header-anchor" href="#项目版本" aria-label="Permalink to &quot;项目版本&quot;">​</a></h2><h1 id="v-0-1-1-mvp" tabindex="-1">V 0.1.1(MVP) <a class="header-anchor" href="#v-0-1-1-mvp" aria-label="Permalink to &quot;V 0.1.1(MVP)&quot;">​</a></h1><h2 id="警告-喜报" tabindex="-1"><s>警告</s> 喜报 <a class="header-anchor" href="#警告-喜报" aria-label="Permalink to &quot;~~警告~~ 喜报&quot;">​</a></h2><ul><li>此版本的Qlora_qwen3.py已经过4090实机测试(generate_training_data_llm.py+run_finetune.py)</li><li>清洗数据也已经进行实机测试(当前版本)</li></ul><h2 id="todo" tabindex="-1">TODO <a class="header-anchor" href="#todo" aria-label="Permalink to &quot;TODO&quot;">​</a></h2><ul><li>[完成]增加unsloth支持(重要!可以加快微调速度)</li></ul><blockquote><p>↑ ↑ ↑ 2025/8/4更新,已支持(实际上之前就能用了,可能是我显卡问题?)</p></blockquote><ul><li>[完成但未测试]增加对MoE模型的支持</li></ul><blockquote><p>↑ ↑ ↑ 2025/8/3更新,或许支持了, 我的显卡跑不动30b a3b,所以还是没法测试<br> 4090的机子塞不下这56.8g的模型,我还是不测了罢(</p></blockquote><ul><li>[完成]为数据清洗增加LLM清洗功能(让成熟的llm来清洗数据,比直接使用算法好得多)</li></ul><blockquote><p>↑ ↑ ↑ 2025/8/3更新,已增加支持,或许不够完善</p></blockquote><ul><li>[完成]将qlora_qwen3.py的print全部改成logger(?这个很简单,我只是因为怕改多了没法测试(4090到期了))</li></ul><blockquote><p>↑ ↑ ↑ 2025/8/4更新,已完成</p></blockquote><h2 id="更新日志" tabindex="-1">更新日志 <a class="header-anchor" href="#更新日志" aria-label="Permalink to &quot;更新日志&quot;">​</a></h2><blockquote><p>写在commit里了,这里实在不想写</p></blockquote>',28)]))}const g=i(o,[["render",r]]);export{p as __pageData,g as default};
