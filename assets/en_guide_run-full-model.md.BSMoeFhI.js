import{_ as t,c as a,o as s,ae as i}from"./chunks/framework.DUP9kEI5.js";const m=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"en/guide/run-full-model.md","filePath":"en/guide/run-full-model.md"}'),d={name:"en/guide/run-full-model.md"};function n(r,e,o,l,h,p){return s(),a("div",null,e[0]||(e[0]=[i('<h2 id="_3-5-not-recommended-run-full-model-directly-after-fine-tuning-recommend-going-directly-to-steps-4-5-6-7-wait-until-converted-to-gguf-and-quantized-before-running" tabindex="-1">3.5 (Not Recommended) Run Full Model Directly After Fine-tuning (Recommend going directly to steps 4,5,6,7, wait until converted to GGUF and quantized before running) <a class="header-anchor" href="#_3-5-not-recommended-run-full-model-directly-after-fine-tuning-recommend-going-directly-to-steps-4-5-6-7-wait-until-converted-to-gguf-and-quantized-before-running" aria-label="Permalink to &quot;3.5 (Not Recommended) Run Full Model Directly After Fine-tuning (Recommend going directly to steps 4,5,6,7, wait until converted to GGUF and quantized before running)&quot;">​</a></h2><h3 id="specify-custom-model-path" tabindex="-1">Specify Custom Model Path <a class="header-anchor" href="#specify-custom-model-path" aria-label="Permalink to &quot;Specify Custom Model Path&quot;">​</a></h3><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> infer_lora_chat.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --base_dir</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-base-model</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --adapter_dir</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-lora-adapter</span></span></code></pre></div><h3 id="use-merged-model" tabindex="-1">Use Merged Model <a class="header-anchor" href="#use-merged-model" aria-label="Permalink to &quot;Use Merged Model&quot;">​</a></h3><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> infer_lora_chat.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --merged</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> true</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --adapter_dir</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-lora-adapter</span></span></code></pre></div><h3 id="adjust-generation-parameters" tabindex="-1">Adjust Generation Parameters <a class="header-anchor" href="#adjust-generation-parameters" aria-label="Permalink to &quot;Adjust Generation Parameters&quot;">​</a></h3><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> infer_lora_chat.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --temperature</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.9</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --top_p</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.95</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --max_new_tokens</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1024</span></span></code></pre></div><h3 id="use-custom-system-prompt" tabindex="-1">Use Custom System Prompt <a class="header-anchor" href="#use-custom-system-prompt" aria-label="Permalink to &quot;Use Custom System Prompt&quot;">​</a></h3><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> infer_lora_chat.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --system_prompt</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;You are a helpful AI assistant.&quot;</span></span></code></pre></div><h3 id="command-line-parameters" tabindex="-1">Command Line Parameters <a class="header-anchor" href="#command-line-parameters" aria-label="Permalink to &quot;Command Line Parameters&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Parameter Name</th><th>Type</th><th>Default Value</th><th>Description</th></tr></thead><tbody><tr><td><code>--base_dir</code></td><td>str</td><td><code>qwen3-8b-base</code></td><td>Base model directory</td></tr><tr><td><code>--adapter_dir</code></td><td>str</td><td><code>finetune/models/qwen3-8b-qlora</code></td><td>LoRA adapter directory</td></tr><tr><td><code>--merged</code></td><td>bool</td><td><code>False</code></td><td>If True, load merged full weights from adapter_dir/merged</td></tr><tr><td><code>--system_prompt</code></td><td>str</td><td>Qing&#39;s digital avatar persona</td><td>Model&#39;s system prompt</td></tr><tr><td><code>--max_new_tokens</code></td><td>int</td><td><code>512</code></td><td>Maximum number of new tokens to generate</td></tr><tr><td><code>--temperature</code></td><td>float</td><td><code>0.7</code></td><td>Sampling temperature</td></tr><tr><td><code>--top_p</code></td><td>float</td><td><code>0.9</code></td><td>Top-p sampling parameter</td></tr><tr><td><code>--trust_remote_code</code></td><td>bool</td><td><code>True</code></td><td>Whether to trust remote code</td></tr></tbody></table>',11)]))}const u=t(d,[["render",n]]);export{m as __pageData,u as default};
