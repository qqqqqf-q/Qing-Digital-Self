import{_ as t,c as a,o as i,ae as o}from"./chunks/framework.DUP9kEI5.js";const g=JSON.parse('{"title":"V 0.1.1","description":"","frontmatter":{},"headers":[],"relativePath":"en/guide/index.md","filePath":"en/guide/index.md"}'),s={name:"en/guide/index.md"};function r(n,e,l,d,c,h){return i(),a("div",null,e[0]||(e[0]=[o('<h2 id="project-introduction" tabindex="-1">Project Introduction <a class="header-anchor" href="#project-introduction" aria-label="Permalink to &quot;Project Introduction&quot;">​</a></h2><h2 id="this-is-a-digital-avatar-project-the-core-idea-is-to-use-qq-s-c2c-chat-records-as-a-dataset-to-fine-tune-large-models-making-the-model-restore-your-unique-expression-style-and-chat-patterns-as-much-as-possible" tabindex="-1">This is a digital avatar project, the core idea is to <strong>use QQ&#39;s C2C chat records as a dataset to fine-tune large models</strong>, making the model restore your unique expression style and chat patterns as much as possible. <a class="header-anchor" href="#this-is-a-digital-avatar-project-the-core-idea-is-to-use-qq-s-c2c-chat-records-as-a-dataset-to-fine-tune-large-models-making-the-model-restore-your-unique-expression-style-and-chat-patterns-as-much-as-possible" aria-label="Permalink to &quot;This is a digital avatar project, the core idea is to **use QQ&#39;s C2C chat records as a dataset to fine-tune large models**, making the model restore your unique expression style and chat patterns as much as possible.&quot;">​</a></h2><p align="center"><img src="https://img.shields.io/badge/Downloads-1-00bfff?style=for-the-badge" style="display:inline-block;margin-right:8px;"><img src="https://img.shields.io/github/stars/qqqqqf-q/Qing-Digital-Self?style=for-the-badge&amp;color=ff69b4" style="display:inline-block;margin-right:8px;"><img src="https://img.shields.io/badge/Status-MVP-ff69b4?style=for-the-badge" style="display:inline-block;margin-right:8px;"><img src="https://img.shields.io/badge/Version-v0.1.1-9370DB?style=for-the-badge" style="display:inline-block;margin-right:8px;"><img src="https://img.shields.io/github/license/qqqqqf-q/Qing-Digital-Self?style=for-the-badge&amp;color=8A2BE2" style="display:inline-block;"></p><h2 id="this-project-includes-a-complete-tutorial-covering" tabindex="-1">This project includes a <strong>complete tutorial</strong>, covering: <a class="header-anchor" href="#this-project-includes-a-complete-tutorial-covering" aria-label="Permalink to &quot;This project includes a **complete tutorial**, covering:&quot;">​</a></h2><ul><li>Decrypting and processing QQ databases</li><li>Cleaning and converting chat data</li><li>QLoRA fine-tuning workflow</li><li>Testing and using fine-tuned models</li><li>Accelerating training with Unsloth!</li></ul><p>I know there are already quite a few similar projects out there, but maybe my tutorial, workflow, and code implementation can offer you something different or spark new ideas. If you find it useful, feel free to give it a star — it’ll make me happy!</p><p>The project still has its shortcomings:</p><ul><li>I’m not sure what they are for now</li><li>(If you run into issues, feel free to open an Issue)</li><li>But it’s already capable of fine-tuning Qwen3-8B with FP8 precision on a 4090 24G GPU (tested and working)</li></ul><p><strong>If you also want to create your own digital persona, give it a try!</strong></p><p>—— X: <a href="https://twitter.com/qqqqqf5" target="_blank" rel="noreferrer">@qqqqqf5</a></p><hr><h2 id="project-version" tabindex="-1">Project Version <a class="header-anchor" href="#project-version" aria-label="Permalink to &quot;Project Version&quot;">​</a></h2><h1 id="v-0-1-1" tabindex="-1">V 0.1.1 <a class="header-anchor" href="#v-0-1-1" aria-label="Permalink to &quot;V 0.1.1&quot;">​</a></h1><h2 id="warning-good-news" tabindex="-1"><s>Warning</s> Good News <a class="header-anchor" href="#warning-good-news" aria-label="Permalink to &quot;~~Warning~~ Good News&quot;">​</a></h2><ul><li>This version of <code>Qlora_qwen3.py</code> has been tested on a 4090 (using <code>generate_training_data_llm.py</code> + <code>run_finetune.py</code>)</li><li>Data cleaning has also been tested on the current version</li></ul><h2 id="todo" tabindex="-1">TODO <a class="header-anchor" href="#todo" aria-label="Permalink to &quot;TODO&quot;">​</a></h2><ul><li>[Completed but untested] Add support for OSS models (and MXFP4? This is a computation for the 50 series, and I still can’t test it myself)</li></ul><blockquote><p>Challenges:</p><ol><li>MOE models</li><li>Non-Qwen series models</li><li>My 3080 seems unable to run local tests (for either fine-tuning or MXFP4) Well, it’s actually not that hard — I’ve just been busy with other projects these past few days.</li></ol></blockquote><h2 id="changelog" tabindex="-1">Changelog <a class="header-anchor" href="#changelog" aria-label="Permalink to &quot;Changelog&quot;">​</a></h2><blockquote><p>Written in the commits — don’t feel like writing it here.</p></blockquote>',20)]))}const p=t(s,[["render",r]]);export{g as __pageData,p as default};
